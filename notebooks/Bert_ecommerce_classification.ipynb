{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fRlbUyxmsitv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from transformers import AutoModel\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QpT3rIsmssUd"
   },
   "outputs": [],
   "source": [
    "base_path = \"../datasets/ecommerce\"\n",
    "df_full = pd.read_csv(f\"{base_path}/sample_products.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T1Ji72MG4m6w"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df_full[\"target\"] = le.fit_transform(df_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ql2dAx0q226-",
    "outputId": "1171b262-68db-496e-b9c5-caa0248dbc6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Micromax Canvas Win W121 (White)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50425 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1  target\n",
       "0        Household  Paper Plane Design Framed Wall Hanging Motivat...       3\n",
       "1        Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...       3\n",
       "2        Household  SAF 'UV Textured Modern Art Print Framed' Pain...       3\n",
       "3        Household  SAF Flower Print Framed Painting (Synthetic, 1...       3\n",
       "4        Household  Incredible Gifts India Wooden Happy Birthday U...       3\n",
       "...            ...                                                ...     ...\n",
       "50420  Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...       2\n",
       "50421  Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...       2\n",
       "50422  Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...       2\n",
       "50423  Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...       2\n",
       "50424  Electronics                   Micromax Canvas Win W121 (White)       2\n",
       "\n",
       "[50425 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tqCo3BHGw7pE"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_full, test_size=0.2, stratify=df_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1lMrnjzvw-MV"
   },
   "outputs": [],
   "source": [
    "# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "list_classes = \"target\"\n",
    "\n",
    "x_train = train[1]\n",
    "y_train = train[list_classes]\n",
    "\n",
    "x_test = test[1]\n",
    "y_test = test[list_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UdzYmMIVXwk2"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "x_test = np.asarray(x_test).astype('str')\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "izz_jfPXw_sb"
   },
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pnkUJJ4xc4mM"
   },
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWSEQVf-dDZF",
    "outputId": "837aecd0-13fc-4eb5-833f-39f653897832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (10, 128)\n",
      "Word Ids   : [  101 25283  5092  6081  5371 19622  2007  2410 10306  1010  5047  1010]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = x_train[:10]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2-uu4EQddHG",
    "outputId": "7ab17c4b-56f8-4551-989a-a4075a59c24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(10, 512)\n",
      "Pooled Outputs Values:[ 0.972496    0.4619606  -0.24892116  0.2246686   0.5346749   0.9987924\n",
      "  0.9808407  -0.7584635  -0.4017263  -0.71385735 -0.09148715 -0.9505471 ]\n",
      "Sequence Outputs Shape:(10, 128, 512)\n",
      "Sequence Outputs Values:[[ 0.8073148  -0.5198374  -0.02489168 ... -0.43454123 -1.1999257\n",
      "   0.54391646]\n",
      " [ 0.75918365 -0.5762162   0.20485923 ... -0.322659   -0.08884247\n",
      "  -0.05090211]\n",
      " [ 0.12971401 -0.7094554   0.7334735  ... -0.0250516  -0.7185406\n",
      "   0.6864215 ]\n",
      " ...\n",
      " [ 0.11033924  0.04044639 -0.4643631  ... -0.09314542  1.0071619\n",
      "   1.6363361 ]\n",
      " [ 0.5230737  -0.60592854  0.02337012 ...  0.23626448 -0.36064634\n",
      "   0.92251474]\n",
      " [-0.00545413  0.51662517  0.04731714 ... -0.5927674   0.6675662\n",
      "   1.2395232 ]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Y_i-AcEw_xsw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WhYOlwB65aAs"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model(num_classes):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    \n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(128, activation=\"relu\")(net)\n",
    "    \n",
    "    \n",
    "    net = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Za9VvYfB6SIv",
    "outputId": "7893bed6-937d-4ac8-deb9-dde97eff27e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 10:32:29.248523: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 62509056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 2, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model = build_classifier_model(num_classes)\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "np.argmax(bert_raw_result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['preprocessing[0][0]',          \n",
      "                                 [(None, 128, 512),               'preprocessing[0][1]',          \n",
      "                                 (None, 128, 512),                'preprocessing[0][2]']          \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                512)}                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 4)            516         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,829,829\n",
      "Trainable params: 28,829,828\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "aOh2USAteBPi"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# steps_per_epoch = num_classes\n",
    "# num_train_steps = steps_per_epoch * epochs\n",
    "# num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# init_lr = 3e-5\n",
    "# optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')\n",
    "\n",
    "\n",
    "# metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()  # categorical = one-hot\n",
    "metrics = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "classifier_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1).element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwkWCgAueBBY",
    "outputId": "42d5b37c-e28e-48d0-8b7a-b6f4d48e5701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 4) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtfhub_handle_encoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;66;43;03m# validation_data=test_ds,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file29vqnvhg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/joker/.virtualenvs/tensorflow_lastest/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 4) are incompatible\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x_train, y_train,\n",
    "                               # validation_data=test_ds,\n",
    "                               callbacks=[callback],\n",
    "                               epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bmhu36KTgr8A",
    "outputId": "94d29aba-fbf0-4500-8aff-efcd5a4a5c8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'toxic'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PCIL6EFGmoVT"
   },
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "    result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "    print(*result_for_printing, sep='\\n')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGF6rs8EjuDN",
    "outputId": "d4d88cae-9a64-47a5-826d-a3a87bfb890c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.14644575 0.12879334 0.30365846 0.42110246]\n",
      " [0.46102217 0.08755876 0.16546461 0.28595456]], shape=(2, 4), dtype=float32)\n",
      "['Household' 'Household' 'Household' 'Household' 'Household' 'Household'\n",
      " 'Household' 'Household' 'Household' 'Household' 'Household' 'Household'\n",
      " 'Household' 'Household' 'Household' 'Household' 'Household' 'Electronics'\n",
      " 'Household' 'Household' 'Household' 'Books' 'Books' 'Household' 'Books'\n",
      " 'Books' 'Household' 'Household' 'Household' 'Books' 'Household'\n",
      " 'Household' 'Household' 'Household' 'Household' 'Household' 'Household'\n",
      " 'Household' 'Household' 'Household' 'Household' 'Electronics' 'Household'\n",
      " 'Books' 'Clothing & Accessories' 'Household' 'Books' 'Household'\n",
      " 'Household' 'Books']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Household', 'Household', 'Household', 'Household', 'Household',\n",
       "       'Household', 'Household', 'Household', 'Household', 'Electronics',\n",
       "       'Clothing & Accessories', 'Clothing & Accessories', 'Household',\n",
       "       'Household', 'Electronics', 'Household', 'Electronics',\n",
       "       'Clothing & Accessories', 'Household', 'Clothing & Accessories',\n",
       "       'Household', 'Household', 'Books', 'Household',\n",
       "       'Clothing & Accessories', 'Books', 'Clothing & Accessories',\n",
       "       'Electronics', 'Electronics', 'Books', 'Household', 'Household',\n",
       "       'Household', 'Electronics', 'Electronics', 'Household',\n",
       "       'Electronics', 'Electronics', 'Electronics', 'Household',\n",
       "       'Household', 'Electronics', 'Household', 'Books', 'Household',\n",
       "       'Household', 'Books', 'Household', 'Clothing & Accessories',\n",
       "       'Books'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    \"anDisk Extreme 64GB CompactFlash Memory Card UDMA 7 Speed Up To 120MB/s 64GB Storage Capacity Read Speed up to 120 MB/s Write Speed up to 85 MB/s UDMA 7 Compliant The SanDisk 64 GB Extreme CompactFlash Memory Card provides fast, reliable photo and video capture. This card features a read speed of up to 120 MB/s and a write speed of up to 85 MB/s. Ultra Direct Memory Access 7 (UDMA-7) ensures optimal performance. When paired with a UDMA-compliant DSLR camera, this card guarantees fast, high-quality photo and video capture. Sustained Performance for Any Situation The optimal combination of shot speed (up to 85MB/s1) sustained video performance guarantee (VPG-20)3, and transfer speed (up to 120MB/s) Ideal for use with mid-range to high-end DSLR cameras and HD camcorders, the SanDisk Extreme CompactFlash Memory Card delivers first-rate read/write speeds to catch fast action shots and enable quick file transfers. This memory card features Video Performance Guarantee (VPG-20) to deliver a minimum sustained recording data rate of 20MB/s3 to support high-quality Full HD video (1080p)4 recording. Take advantage of burst-mode photography with the card's write speeds of up to 85MB/s1 (567X) and enjoy efficient workflow with its transfer speeds up to 120MB/s2. With capacities up to 128GB5, this memory card provides plenty of storage for Full HD videos and RAW photos. Exceptional Shot to Shot Performance With write speeds of up to 85MB/s1, the SanDisk Extreme CompactFlash Memory Card adds to your mid-range to-high-range DSLR's performance during burst-mode shooting, rapid shots, and RAW plus JPEG capture. The card records photos almost instantly, ensuring you will catch your best shot. Read speeds of up to 120MB/s2 make transferring images to your computer fast and simple. Professional-Grade Video Capture Featuring a Video Performance Guarantee (VPG-20)3 profile specification, the SanDisk Extreme CompactFlash memory card can keep up with the steep memory demands of professional video equipment such as HD camcorders\",\n",
    "    \"Dell KB216 (HVG5J) Multimedia Keyboard (Black) Progress lives at the intersection of technology and humanity. Our connected world is undergoing its latest digital transformation-changing industries and creating fundamental shifts in the way we work and live.\"\n",
    "]\n",
    "\n",
    "print(classifier_model(tf.constant(examples)))\n",
    "\n",
    "original_results = classifier_model(tf.constant(x_test[:50]))\n",
    "predictions = np.argmax(original_results, axis=1)\n",
    "\n",
    "print(le.inverse_transform(predictions))\n",
    "le.inverse_transform(y_test[:50])\n",
    "\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhDcjjGegvFI"
   },
   "outputs": [],
   "source": [
    "# serving_results = reloaded_model \\\n",
    "#             .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "# serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "# print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q94XwguUmTjB"
   },
   "outputs": [],
   "source": [
    "/content/toxic_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9KV0fXyshEFo",
    "outputId": "fbeede7a-04f4-446b-ea3e-10bc3d3074ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/gdrive/MyDrive/models/bert'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "dest = \"/gdrive/MyDrive/models/bert\"\n",
    "\n",
    "shutil.copytree(saved_model_path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu1E_Q2_6Wyr"
   },
   "outputs": [],
   "source": [
    "# max_seq_length = 128\n",
    "\n",
    "# packer = tfm.nlp.layers.BertPackInputs(\n",
    "#     seq_length=max_seq_length,\n",
    "#     special_tokens_dict = tokenizer.get_special_tokens_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bia03Sy6YBb"
   },
   "outputs": [],
   "source": [
    "# class BertInputProcessor(tf.keras.layers.Layer):\n",
    "#   def __init__(self, tokenizer, packer):\n",
    "#     super().__init__()\n",
    "#     self.tokenizer = tokenizer\n",
    "#     self.packer = packer\n",
    "\n",
    "#   def call(self, inputs):\n",
    "#     tok1 = self.tokenizer(inputs)\n",
    "\n",
    "#     packed = self.packer(tok1)\n",
    "\n",
    "#     return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzY5iHdV62Y7"
   },
   "outputs": [],
   "source": [
    "# bert_inputs_processor = BertInputProcessor(tokenizer, packer)\n",
    "\n",
    "# x_train_ds = bert_inputs_processor(x_train[:1000])\n",
    "# example_inputs = next(iter(x_train_ds))\n",
    "\n",
    "# example_inputs\n",
    "# import json\n",
    "\n",
    "# bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
    "# config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
    "# config_dict\n",
    "# encoder_config = tfm.nlp.encoders.EncoderConfig({\n",
    "#     'type':'bert',\n",
    "#     'bert': config_dict\n",
    "# })\n",
    "\n",
    "# bert_encoder = tfm.nlp.encoders.build_encoder(encoder_config)\n",
    "# bert_encoder\n",
    "# bert_classifier = tfm.nlp.models.BertClassifier(network=bert_encoder, num_classes=6)\n",
    "# tf.keras.utils.plot_model(bert_classifier, show_shapes=True, dpi=48)\n",
    "\n",
    "# x_train_ds\n",
    "# bert_classifier(\n",
    "#     x_train_ds, training=True).numpy()[:10]\n",
    "# # y_cat_train = np.argmax(y_train.values, axis=1)\n",
    "# # y_cat_test = np.argmax(y_test.values, axis=1)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_data, y_train)).batch(64)\n",
    "# # test_dataset = tf.data.Dataset.from_tensor_slices((test_data, y_test)).batch(64)\n",
    "# bert_classifier, bert_encoder = classifier_model(bert_config, num_labels=6)\n",
    "# checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
    "# checkpoint.read(\n",
    "#     os.path.join(gs_folder_bert, 'bert_model.ckpt')).assert_consumed()\n",
    "# # Set up epochs and steps\n",
    "# epochs = 3\n",
    "# batch_size = 32\n",
    "# eval_batch_size = 32\n",
    "\n",
    "# train_data_size = len(y_train)\n",
    "# steps_per_epoch = int(train_data_size / batch_size)\n",
    "# num_train_steps = steps_per_epoch * epochs\n",
    "# warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "# # creates an optimizer with learning rate schedule\n",
    "# optimizer = nlp.optimization.create_optimizer(\n",
    "#     2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\n",
    "\n",
    "\n",
    "# metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# bert_classifier.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss=loss,\n",
    "#     metrics=metrics)\n",
    "\n",
    "\n",
    "# history = bert_classifier.fit(\n",
    "#       train_data,\n",
    "#       epochs=epochs)\n",
    "# train_data\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert ecommerce classification.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
